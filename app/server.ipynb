{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6e26fd",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import StreamingResponse\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2794175",
   "metadata": {},
   "source": [
    "### fastapiアプリの作成とパイプライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eaada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "# DeepLabV3 + ResNet50（COCOデータセットで学習済み）を読み込み 推論モードに設定\n",
    "model = deeplabv3_resnet50(pretrained=True).eval()\n",
    "# 画像前処理パイプライン\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55742c9a",
   "metadata": {},
   "source": [
    "### 逐次実行用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像ファイルの読み込み\n",
    "img_path = \"test.jpg\"  \n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "plt.imshow(img,cmap=\"jet\")\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 前処理を適用\n",
    "print('処理前',img.size)\n",
    "input_tensor = transform(img)\n",
    "print('transform後',input_tensor.shape)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # (1, C, H, W)\n",
    "print('unsqueeze後',input_tensor.shape)\n",
    "print(type(input_tensor))\n",
    "# 4. 推論\n",
    "# 勾配計算をオフにする,既に推論モードになっている\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    print(output.keys())\n",
    "    output = output['out'][0]  # (num_classes, H, W)\n",
    "    preds = output.argmax(0).byte().cpu().numpy()  # 各ピクセルのクラスID\n",
    "    print(output.shape)\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7213497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. マスク生成（クラス15=person）\n",
    "mask = (preds == 15).astype(np.uint8) * 255\n",
    "print(mask.shape)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Person Mask (class=15)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 元画像にオーバーレイ\n",
    "np_img = np.array(img)  # 元画像サイズのまま\n",
    "print(np_img.shape)\n",
    "h0, w0 = np_img.shape[:2]\n",
    "print(h0,w0)\n",
    "# mask を元画像サイズに拡大/縮小,最近傍補間（INTER_NEAREST）を使うことでクラス境界がぼけません\n",
    "mask_up = cv2.resize(mask, (w0, h0), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "overlay = np_img.copy()\n",
    "overlay[mask_up == 255] = [0, 0, 255]\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Overlay (Red on Person)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. ブレンド合成\n",
    "blended = cv2.addWeighted(np_img, 0.6, overlay, 0.4, 0)\n",
    "plt.imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Blended Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. JPEGエンコードして保存（StreamingResponseの代わりに保存）\n",
    "_, jpeg = cv2.imencode(\".jpg\", blended)\n",
    "with open(\"result.jpg\", \"wb\") as f:\n",
    "    f.write(jpeg.tobytes())\n",
    "\n",
    "print(\"処理完了: result.jpg に結果画像を保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5bdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9dec8f",
   "metadata": {},
   "source": [
    "### エンドポイント作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォームデータとして画像ファイル(UploadFile)を受け取る\n",
    "@app.post(\"/api/detect\")\n",
    "async def detect(file: UploadFile = File(...)):\n",
    "    img = Image.open(file.file).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)['out'][0]\n",
    "        preds = output.argmax(0).byte().cpu().numpy()\n",
    "\n",
    "    mask = (preds == 15).astype(np.uint8) * 255\n",
    "    np_img = np.array(img)\n",
    "    overlay = np_img.copy()\n",
    "    overlay[mask == 255] = [0, 0, 255]\n",
    "    blended = cv2.addWeighted(np_img, 0.6, overlay, 0.4, 0)\n",
    "\n",
    "    _, jpeg = cv2.imencode(\".jpg\", blended)\n",
    "    return StreamingResponse(io.BytesIO(jpeg.tobytes()), media_type=\"image/jpeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6828b02",
   "metadata": {},
   "source": [
    "### 起動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "    # uvicorn server_node:app --host 0.0.0.0 --port 8080\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
